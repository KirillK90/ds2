{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2 по обработке текстов\n",
    "\n",
    "Рассмотрим задачу бинарной классификации. Пусть дано два списка имен: мужские и женские имена. Требуется разработать классификатор, который по данному имени будет определять мужское оно или женское.\n",
    "\n",
    "Данные: \n",
    "* Женские имена: female.txt\n",
    "* Мужские имена: male.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Предварительная обработка данных\n",
    "\n",
    "1. Удалите неоднозначные имена (те имена, которые являются и мужскими, и женскими дновременно), если такие есть; \n",
    "2. Создайте обучающее и тестовое множество так, чтобы в обучающем множестве классы были сбалансированы, т.е. к классу принадлежало бы одинаковое количество имен;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "names    7944\n",
       "sex      7944\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "male = pd.read_csv('male.txt', header=None, names = [\"names\"])\n",
    "female = pd.read_csv('female.txt', header=None, names = [\"names\"])\n",
    "male[\"sex\"] = 1\n",
    "female[\"sex\"] = 0\n",
    "tmp = male.copy()\n",
    "tmp = tmp.append(female, ignore_index=True)\n",
    "tmp.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим повторяющиеся имена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.drop_duplicates('names',keep=False,inplace=True) \n",
    "testPart = 0.1 #Доля тестовой быборки\n",
    "testPart = int(testPart * tmp.count()[0] / 2) #Рассчитаем так, чтобы число мужчин и женщин было равно\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tmp[:testPart]\n",
    "X_test = X_test.append(tmp[-testPart:])\n",
    "X_test.count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6494"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = tmp[testPart:-testPart]\n",
    "X_train.count()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим правильность деления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tmp.count()[0] == (X_test.count()[0] + X_train.count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделим y_test и y_train и удалим их из X_test и X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test = X_test[\"sex\"]\n",
    "y_train = X_train[\"sex\"]\n",
    "X_test.drop('sex', axis=1);\n",
    "X_train.drop('sex', axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 2. Базовый метод классификации\n",
    "\n",
    "Используйте метод наивного Байеса или логистическую регрессию для классификации имен: в качестве признаков используйте символьные $n$-граммы. Сравните результаты, получаемые при разных $n=2,3,4$ по $F$-мере и аккуратности. В каких случаях метод ошибается?\n",
    "\n",
    "Для генерации $n$-грамм используйте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 3. Нейронная сеть\n",
    "\n",
    "\n",
    "Используйте  реккурентную нейронную сеть с  LSTM для решения задачи. В ней может быть несколько слоев с LSTM, несколько слоев c Bidirectional(LSTM).  У нейронной сети один выход, определяющий класс имени. \n",
    "\n",
    "Представление имени для классификации в этом случае: бинарная матрица размера (количество букв в алфавите $\\times$ максимальная длина имени). Обозначим его через $x$. Если первая буква имени a, то $x[1][1] = 1$, если вторая – b, то  $x[2][1] = 1$.  \n",
    "\n",
    "Не забудьте про регуляризацию нейронной сети дропаутами. \n",
    "\n",
    "Сравните результаты классификации разными методами. Какой метод лучше и почему?\n",
    "\n",
    "Сравните результаты, получаемые при разных значениях дропаута, разных числах узлов на слоях нейронной сети по $F$-мере и аккуратности. В каких случаях нейронная сеть ошибается?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "total endtries  7214\n",
      "max len  32\n",
      "total chars: 30\n",
      "Build model...\n",
      "Epoch 1/10\n",
      "7214/7214 [==============================] - 297s 41ms/step - loss: 0.7138\n",
      "Epoch 2/10\n",
      "7214/7214 [==============================] - 308s 43ms/step - loss: 0.6652\n",
      "Epoch 3/10\n",
      " 320/7214 [>.............................] - ETA: 4:38 - loss: 0.6545"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras import __version__ as keras_version\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "nEpochs = 10\n",
    "weightsFileName = \"gender_weights.h5\"\n",
    "\n",
    "\n",
    "print (\"loading data\")\n",
    "\n",
    "with open(\"male.txt\") as f:\n",
    "    m_names = f.readlines()\n",
    "\n",
    "with open(\"female.txt\") as f:\n",
    "    f_names = f.readlines()\n",
    "\n",
    "mf_names = []\n",
    "\n",
    "for f_name in f_names:\n",
    "\tif f_name in m_names:\n",
    "\t\tmf_names.append(f_name)\n",
    "\n",
    "m_names = [m_name.lower() for m_name in m_names if not m_name in mf_names]\n",
    "f_names = [f_name.lower() for f_name in f_names if not f_name in mf_names]\n",
    "\n",
    "\n",
    "totalEntries = len(m_names) + len(f_names)\n",
    "maxlen = len(max( m_names , key=len)) + len(max( f_names , key=len))\n",
    "\n",
    "chars = set(  \"\".join(m_names) + \"\".join(f_names)  )\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "print (\"total endtries \" , totalEntries)\n",
    "print (\"max len \" , maxlen)\n",
    "print('total chars:', len(chars))\n",
    "\n",
    "\n",
    "\n",
    "X = np.zeros((totalEntries , maxlen, len(chars) ), dtype=np.bool)\n",
    "y = np.zeros((totalEntries , 2 ), dtype=np.bool)\n",
    "\n",
    "\n",
    "for i, name in enumerate(m_names):\n",
    "    for t, char in enumerate(name):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, 0 ] = 1\n",
    "\n",
    "for i, name in enumerate(f_names):\n",
    "    for t, char in enumerate(name):\n",
    "        X[i + len(m_names), t, char_indices[char]] = 1\n",
    "    y[i + len(m_names) , 1 ] = 1\n",
    "\n",
    "def vec2c(vec):\n",
    "\tfor i,v in enumerate(vec):\n",
    "\t\tif v:\n",
    "\t\t\treturn indices_char[i]\n",
    "\treturn \"\"\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "\n",
    "json_string = model.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as text_file:\n",
    "    text_file.write(json_string)\n",
    "\n",
    "\n",
    "if keras_version[0] == '1':\n",
    "\tmodel.fit(X, y, batch_size=16, nb_epoch=nEpochs)\n",
    "else:\n",
    "\tmodel.fit(X, y, batch_size=16, epochs=nEpochs)\n",
    "\n",
    "model.save_weights('my_model_weights.h5')\n",
    "\n",
    "print (\"done and weights saved\")\n",
    "score = model.evaluate(X, y, batch_size=16)\n",
    "print (\"score \" , score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "def predict(model, name, maxlen, chars, char_indices):\n",
    "\tx = np.zeros((1, maxlen, len(chars)))\n",
    "\tfor t, char in enumerate(name):\n",
    "\t\tx[0, t, char_indices[char]] = 1\n",
    "\n",
    "\tpreds = model.predict(x, verbose=0)[0]\n",
    "\treturn preds\n",
    "\n",
    "\n",
    "def load_model(maleFile, femaleFile):\n",
    "\tmf_names = []\n",
    "\twith open(maleFile) as f:\n",
    "\t\tm_names = f.readlines()\n",
    "\n",
    "\twith open(femaleFile) as f:\n",
    "\t\tf_names = f.readlines()\n",
    "\n",
    "\tfor f_name in f_names:\n",
    "\t\tif f_name in m_names:\n",
    "\t\t\tmf_names.append(f_name)\n",
    "\n",
    "\tm_names = [m_name.lower() for m_name in m_names if not m_name in mf_names]\n",
    "\tf_names = [f_name.lower() for f_name in f_names if not f_name in mf_names]\n",
    "\n",
    "\ttotalEntries = len(m_names) + len(f_names)\n",
    "\tmaxlen = len(max( m_names , key=len)) + len(max( f_names , key=len))\n",
    "\n",
    "\tchars = set(  \"\".join(m_names) + \"\".join(f_names)  )\n",
    "\tchar_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\tindices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\twith open(\"model.json\", 'r') as content_file:\n",
    "\t\tjson_string = content_file.read()\n",
    "\n",
    "\tmodel = model_from_json(json_string)\n",
    "\tmodel.load_weights('my_model_weights.h5')\n",
    "\treturn model, maxlen ,chars ,char_indices\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmodel, maxlen, chars, char_indices = load_model(sys.argv[1], sys.argv[2])\n",
    "\twhile True:\n",
    "\t\t(print \"Enter any name:\")\n",
    "\t\tn = raw_input()\n",
    "\t\tv = predict(model, n, maxlen, chars, char_indices)\n",
    "\t\tif v[0] > v[1]:\n",
    "\t\t\t(print \"Male\")\n",
    "\t\telse:\n",
    "\t\t\t(print \"Female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если совсем не получается запрограммировать нейронную сеть самостоятельно, обратитесь к туториалу тут: https://github.com/divamgupta/lstm-gender-predictor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
